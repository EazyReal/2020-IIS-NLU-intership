{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-123-3592803382a5>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-123-3592803382a5>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    from tqdm import tqdm.notebook.tqdm as tqdm\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "import torch\n",
    "import random\n",
    "import pickle\n",
    "import glob\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm.notebook.tqdm as tqdm\n",
    "import config\n",
    "import utils\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001acaa8fabb4bfebc4ffa32ed234426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "glove = {}\n",
    "emb_file = config.GLOVE\n",
    "with open(emb_file, 'r', encoding=\"utf-8\") as fo:\n",
    "    lines = fo.readlines()\n",
    "    for line in tqdm(lines):\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        glove[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.2028   0.44239  0.61904 -0.11624 -0.33635 -0.24591]\n",
      "1917494\n"
     ]
    }
   ],
   "source": [
    "print(glove[\"obama\"][:6])\n",
    "print(len(glove))\n",
    "# to do handle OOV embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file=config.DEV_MA_FILE\n",
    "emb=config.GLOVE\n",
    "parser=None\n",
    "save=False\n",
    "target=config.PDEV_MA_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63735n\n"
     ]
    }
   ],
   "source": [
    "with open(data_file) as fo:\n",
    "    raw_lines = fo.readlines()\n",
    "    json_data = [json.loads(line) for line in raw_lines]\n",
    "print(json_data[0][config.idf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 14:17:18 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2020-07-31 14:17:18 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| pos       | ewt     |\n",
      "| lemma     | ewt     |\n",
      "| depparse  | ewt     |\n",
      "=======================\n",
      "\n",
      "2020-07-31 14:17:18 INFO: Use device: gpu\n",
      "2020-07-31 14:17:18 INFO: Loading: tokenize\n",
      "2020-07-31 14:17:18 INFO: Loading: pos\n",
      "2020-07-31 14:17:19 INFO: Loading: lemma\n",
      "2020-07-31 14:17:19 INFO: Loading: depparse\n",
      "2020-07-31 14:17:21 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,depparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 120kB [00:00, 394kB/s]                     \n",
      "2020-07-31 14:30:20 INFO: \"zh\" is an alias for \"zh-hans\"\n",
      "2020-07-31 14:30:20 INFO: Downloading default packages for language: zh-hans (Simplified_Chinese)...\n",
      "Downloading http://nlp.stanford.edu/software/stanza/1.0.0/zh-hans/default.zip: 100%|██████████| 678M/678M [07:09<00:00, 1.58MB/s] \n",
      "2020-07-31 14:37:41 INFO: Finished downloading models and saved to /root/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Barack Obama was born in Hawaii.  He was elected president in 2008.\")\n",
    "dir(doc)\n",
    "stanza.download('zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_dependencies', 'build_dependencies', 'dependencies', 'dependencies_string', 'print_dependencies']\n"
     ]
    }
   ],
   "source": [
    "dep_r = [line for line in dir(nlp(json_data[0][config.hf]).sentences[0]) if \"dep\" in line]\n",
    "print(dep_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = []\n",
    "for data in json_data:\n",
    "    #process_sentance()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: Barack\thead id: 4\thead: born\tdeprel: nsubj:pass\n",
      "id: 2\tword: Obama\thead id: 1\thead: Barack\tdeprel: flat\n",
      "id: 3\tword: was\thead id: 4\thead: born\tdeprel: aux:pass\n",
      "id: 4\tword: born\thead id: 0\thead: root\tdeprel: root\n",
      "id: 5\tword: in\thead id: 6\thead: Hawaii\tdeprel: case\n",
      "id: 6\tword: Hawaii\thead id: 4\thead: born\tdeprel: obl\n",
      "id: 7\tword: .\thead id: 4\thead: born\tdeprel: punct\n",
      "id: 1\tword: He\thead id: 3\thead: elected\tdeprel: nsubj:pass\n",
      "id: 2\tword: was\thead id: 3\thead: elected\tdeprel: aux:pass\n",
      "id: 3\tword: elected\thead id: 0\thead: root\tdeprel: root\n",
      "id: 4\tword: president\thead id: 3\thead: elected\tdeprel: xcomp\n",
      "id: 5\tword: in\thead id: 6\thead: 2008\tdeprel: case\n",
      "id: 6\tword: 2008\thead id: 3\thead: elected\tdeprel: obl\n",
      "id: 7\tword: .\thead id: 3\thead: elected\tdeprel: punct\n"
     ]
    }
   ],
   "source": [
    "utils.print_compact_dep(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Everyone', '3', 'nsubj')\n",
      "('really', '3', 'advmod')\n",
      "('likes', '0', 'root')\n",
      "('the', '6', 'det')\n",
      "('newest', '6', 'amod')\n",
      "('benefits', '3', 'obj')\n"
     ]
    }
   ],
   "source": [
    "nlp(json_data[0][config.hf]).sentences[0].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp(json_data[0][config.hf]).sentences[0].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "x = torch.tensor([[2,1],[5,6],[3,7],[12,0]],dtype=torch.float)\n",
    "\n",
    "y = torch.tensor([[0,2,1,0,3],[3,1,0,1,2]],dtype=torch.long)\n",
    "\n",
    "edge_index = torch.tensor([[0, 1],\n",
    "                           [1, 0],\n",
    "                           [2, 1],\n",
    "                           [0, 3],\n",
    "                           [2, 3]], dtype=torch.long)\n",
    "\n",
    "data = Data(x=x,y=y,edge_index=edge_index.contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.is_directed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__apply__',\n",
       " '__call__',\n",
       " '__cat_dim__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__inc__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'apply',\n",
       " 'clone',\n",
       " 'coalesce',\n",
       " 'contains_isolated_nodes',\n",
       " 'contains_self_loops',\n",
       " 'contiguous',\n",
       " 'debug',\n",
       " 'edge_attr',\n",
       " 'edge_index',\n",
       " 'face',\n",
       " 'from_dict',\n",
       " 'is_coalesced',\n",
       " 'is_directed',\n",
       " 'is_undirected',\n",
       " 'keys',\n",
       " 'norm',\n",
       " 'num_edge_features',\n",
       " 'num_edges',\n",
       " 'num_faces',\n",
       " 'num_features',\n",
       " 'num_node_features',\n",
       " 'num_nodes',\n",
       " 'pos',\n",
       " 'to',\n",
       " 'x',\n",
       " 'y']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
